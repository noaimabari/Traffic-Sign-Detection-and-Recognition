{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the German Traffic Sign Detection Benchmark dataset to TFRecord for object_detection using tensorflow API\n",
    "\n",
    "\n",
    "import hashlib\n",
    "import io\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from object_detection.utils import dataset_util\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "flags.DEFINE_string('data_dir', '', 'Root directory to raw gtsdb dataset.')\n",
    "flags.DEFINE_string('output_dir', '', 'Path to directory to output TFRecords.')\n",
    "flags.DEFINE_string('label_map_path', 'data/gtsdb_label_map.pbtxt',\n",
    "                    'Path to label map proto')\n",
    "FLAGS = flags.FLAGS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--data_dir\", required=True, help=\"Root directory to raw gtsdb dataset\")\n",
    "ap.add_argument(\"-o\", \"--output_dir\", required=True, help=\"Path to directory to output TFRecords\")\n",
    "ap.add_argument(\"-l\", \"--label_map_path\", required = True, help=\"path to label_map.pbtxt\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"data_dir\"] = \"C:\\\\Users\\\\noaim\\\\Downloads\\\\FullIJCNN2013\\\\FullIJCNN2013\"\n",
    "args[\"output_dir\"] = \"C:\\\\Users\\\\noaim\\\\Downloads\\\\FullIJCNN2013\\\\FullIJCNN2013\"\n",
    "args[\"label_map_path\"] = \"C:\\\\Users\\\\noaim\\\\Downloads\\\\FullIJCNN2013\\\\FullIJCNN2013\\\\label_map.pbtxt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting ppm files to jpg for using tensorflow tf record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import os\n",
    "import shutil\n",
    "\n",
    "data_dir = args[\"data_dir\"]\n",
    "#train_img_dir = os.path.join(data_dir, 'TrainIJCNN2013')\n",
    "img_dir = os.path.join(data_dir)\n",
    "jpg_img_dir = os.path.join(data_dir, 'jpg_FullIJCNN2013')\n",
    "\n",
    "\n",
    "if os.path.exists(jpg_img_dir):\n",
    "    shutil.rmtree(jpg_img_dir)\n",
    "os.makedirs(jpg_img_dir) \n",
    "\n",
    "for img_name in os.listdir(img_dir):\n",
    "#for img_name in [\"00000.ppm\",\"00001.ppm\",\"00002.ppm\"]:\n",
    "    if img_name[-3:] == \"ppm\":\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        jpg_path = os.path.join(jpg_img_dir, img_name[:-3]+'jpg')\n",
    "        #print(png_path)\n",
    "        img.save(jpg_path)\n",
    "        #img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to get dictionary of class id and class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_dict(label_path):\n",
    "    label_map_dict = {}\n",
    "    with open(label_path, 'r', encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if not line.split():\n",
    "                continue\n",
    "            line = line.strip()\n",
    "            number, name = line.split(' ', 1)\n",
    "            label_map_dict[int(number)+1] = name\n",
    "    return label_map_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_tf_example(data, label_map_dict, image_subdirectory):\n",
    "    img_path = os.path.join(image_subdirectory, data['filename'])\n",
    "    with tf.gfile.GFile(img_path, 'rb') as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
    "    image = PIL.Image.open(encoded_jpg_io)\n",
    "    if image.format != 'JPEG':\n",
    "        raise ValueError('Image format not JPEG')\n",
    "    key = hashlib.sha256(encoded_jpg).hexdigest()\n",
    "\n",
    "    width, height = image.size\n",
    "\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    classes = []\n",
    "    classes_text = []\n",
    "    \n",
    "    for obj in data['object']:\n",
    "\n",
    "        xmin.append(float(obj['bndbox']['xmin']) / width)\n",
    "        ymin.append(float(obj['bndbox']['ymin']) / height)\n",
    "        xmax.append(float(obj['bndbox']['xmax']) / width)\n",
    "        ymax.append(float(obj['bndbox']['ymax']) / height)\n",
    "        class_name = label_map_dict[obj['class']]\n",
    "        classes_text.append(class_name.encode('utf8'))\n",
    "        classes.append(obj['class'])\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(\n",
    "            data['filename'].encode('utf8')),\n",
    "        'image/source_id': dataset_util.bytes_feature(\n",
    "            data['filename'].encode('utf8')),\n",
    "        'image/key/sha256': dataset_util.bytes_feature(key.encode('utf8')),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature('jpeg'.encode('utf8')),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmin),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmax),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymin),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymax),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to create tf record\n",
    "\n",
    "def create_tf_record(output_filename, label_map_dict, gt_path, image_dir, examples):\n",
    "\n",
    "    writer = tf.python_io.TFRecordWriter(output_filename)\n",
    "\n",
    "    # Read ground truth csv\n",
    "    df = pd.read_csv(gt_path, delimiter=';', names=('file', 'xMin', 'yMin', 'xMax', 'yMax', 'classId'))\n",
    "    df['file'] = df['file'].str.replace('ppm', 'jpg')\n",
    "\n",
    "    for idx, example in enumerate(examples):\n",
    "        if idx % 100 == 0:\n",
    "            logging.info('On image %d of %d', idx, len(examples))\n",
    "\n",
    "        data = {\n",
    "            'filename': example,\n",
    "            'object': []\n",
    "        }\n",
    "        objects = df[df['file'] == example]\n",
    "        for _, obj in objects.iterrows():\n",
    "            class_id = obj['classId'] + 1\n",
    "            data['object'].append({\n",
    "                'bndbox': {\n",
    "                    'xmin': obj['xMin'],\n",
    "                    'ymin': obj['yMin'],\n",
    "                    'xmax': obj['xMax'],\n",
    "                    'ymax': obj['yMax']\n",
    "                },\n",
    "                'class': class_id\n",
    "            })\n",
    "        #print(data)\n",
    "        tf_example = df_to_tf_example(data, label_map_dict, image_dir)\n",
    "        writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0706 02:52:35.305810  6560 <ipython-input-6-7ca262d29d3d>:9] Reading from GTSDB dataset.\n",
      "I0706 02:52:35.305810  6560 <ipython-input-6-7ca262d29d3d>:18] 600 training and 300 validation examples.\n",
      "I0706 02:52:35.323721  6560 <ipython-input-5-b421cf493828>:13] On image 0 of 600\n",
      "I0706 02:52:35.623880  6560 <ipython-input-5-b421cf493828>:13] On image 100 of 600\n",
      "I0706 02:52:35.874686  6560 <ipython-input-5-b421cf493828>:13] On image 200 of 600\n",
      "I0706 02:52:36.169329  6560 <ipython-input-5-b421cf493828>:13] On image 300 of 600\n",
      "I0706 02:52:36.424351  6560 <ipython-input-5-b421cf493828>:13] On image 400 of 600\n",
      "I0706 02:52:36.667667  6560 <ipython-input-5-b421cf493828>:13] On image 500 of 600\n",
      "I0706 02:52:37.263319  6560 <ipython-input-5-b421cf493828>:13] On image 0 of 300\n",
      "I0706 02:52:37.541632  6560 <ipython-input-5-b421cf493828>:13] On image 100 of 300\n",
      "I0706 02:52:37.789393  6560 <ipython-input-5-b421cf493828>:13] On image 200 of 300\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\noaim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(_):\n",
    "    #data_dir = FLAGS.data_dir\n",
    "    data_dir = args[\"data_dir\"]\n",
    "\n",
    "    #label_map_dict = label_map_util.get_label_map_id_dict(FLAGS.label_map_path)\n",
    "\n",
    "    label_map_dict = get_label_dict(\"C:\\\\Users\\\\noaim\\\\Downloads\\\\FullIJCNN2013\\\\FullIJCNN2013\\\\gtsdb_labels.txt\")\n",
    "\n",
    "    logging.info('Reading from GTSDB dataset.')\n",
    "    image_dir = os.path.join(data_dir, 'jpg_FullIJCNN2013') \n",
    "    examples_gt_path = os.path.join(data_dir, 'gt.txt')\n",
    "    examples_list = ['%05d.jpg' % x for x in range(900)]\n",
    "\n",
    "    num_train = 600\n",
    "    train_examples = examples_list[:num_train]\n",
    "    val_examples = examples_list[num_train:]\n",
    "    logging.info('%d training and %d validation examples.',\n",
    "                 len(train_examples), len(val_examples))\n",
    "\n",
    "    train_output_path = os.path.join(args[\"output_dir\"], 'gtsdb_train.record')\n",
    "    val_output_path = os.path.join(args[\"output_dir\"], 'gtsdb_val.record')\n",
    "    create_tf_record(train_output_path, label_map_dict, examples_gt_path,\n",
    "                     image_dir, train_examples)\n",
    "    \n",
    "    create_tf_record(val_output_path, label_map_dict, examples_gt_path,\n",
    "                     image_dir, val_examples)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_num_classes(\"C:\\\\Users\\\\noaim\\\\Downloads\\\\FullIJCNN2013\\\\FullIJCNN2013\\\\label_map.pbtxt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
